@String{pub-AW          = "Ad{\-d}i{\-s}on-Wes{\-l}ey"}
@String{pub-AW:adr      = "Reading, MA, USA"}

@article{mnih-dqn-2015,
    Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    Day = {26},
    Journal = {Nature},
    Month = {02},
    Number = {7540},
    Pages = {529--533},
    Title = {Human-level control through deep reinforcement learning},
    Url = {http://dx.doi.org/10.1038/nature14236},
    Volume = {518},
    Year = {2015},
}

@misc{sander_dieleman_2015_27878,
  author       = {Sander Dieleman and
                  Jan Schlüter and
                  Colin Raffel and
                  Eben Olson and
                  Søren Kaae Sønderby and
                  Daniel Nouri and
                  Daniel Maturana and
                  Martin Thoma and
                  Eric Battenberg and
                  Jack Kelly and
                  Jeffrey De Fauw and
                  Michael Heilman and
                  diogo149 and
                  Brian McFee and
                  Hendrik Weideman and
                  takacsg84 and
                  peterderivaz and
                  Jon and
                  instagibbs and
                  Dr. Kashif Rasul and
                  CongLiu and
                  Britefury and
                  Jonas Degrave},
  title        = {Lasagne: First release.},
  month        = aug,
  year         = 2015,
  doi          = {10.5281/zenodo.27878},
  url          = {http://dx.doi.org/10.5281/zenodo.27878}
}

@MISC{Bastien-Theano-2012,
        author = {Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Bergstra, James and Goodfellow, Ian J. and Bergeron, Arnaud and Bouchard, Nicolas and Bengio, Yoshua},
         title = {Theano: new features and speed improvements},
          year = {2012},
  howpublished = {Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop},
      abstract = {Theano is a linear algebra compiler that optimizes a user’s symbolically-speciﬁed
mathematical computations to produce efﬁcient low-level implementations. In
this paper, we present new features and efﬁciency improvements to Theano, and
benchmarks demonstrating Theano’s performance relative to Torch7, a recently
introduced machine learning library, and to RNNLM, a C++ library targeted at
recurrent neural networks.}
}

@INPROCEEDINGS{bergstra+al:2010-scipy,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6× to 7.5× faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}
