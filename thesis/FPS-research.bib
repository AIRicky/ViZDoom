@inproceedings{6374142,
abstract = {Reinforcement learning is a popular machine learning technique whose inherent self-learning ability has made it the candidate of choice for game AI. In this work we propose an expert player based by further enhancing our proposed basic strategies on Ludo. We then implement a TD($\lambda$)based Ludo player and use our expert player to train this player. We also implement a Q-learning based Ludo player using the knowledge obtained from building the expert player. Our results show that while our TD($\lambda$) and Q-Learning based Ludo players outperform the expert player, they do so only slightly suggesting that our expert player is a tough opponent. Further improvements to our RL players may lead to the eventual development of a near-optimal player for Ludo.},
author = {Alhajry, M and Alvi, F and Ahmed, M},
booktitle = {Computational Intelligence and Games (CIG), 2012 IEEE Conference on},
doi = {10.1109/CIG.2012.6374142},
keywords = {Conferences,Games,Learning,Learning systems,Ludo,Q-learning based Ludo players,RL,TD($\lambda$) based Ludo players,Training,Vectors,artificial intelligence,computer games,learning (artificial intelligence),reinforcement learning,self-learning ability},
mendeley-tags = {Ludo,RL},
month = {sep},
pages = {83--90},
title = {{TD( {\#}x03BB;) and Q-learning based Ludo players}},
year = {2012}
}
@inproceedings{choi2007believable,
author = {Choi, Dongkyu and K{\"{o}}nik, Tolga and Nejati, Negin and Park, Chunki and Langley, Pat},
booktitle = {AIIDE},
keywords = {Urban Combat},
mendeley-tags = {Urban Combat},
pages = {71--73},
title = {{A Believable Agent for First-Person Shooter Games.}},
year = {2007}
}
@inproceedings{cole2004using,
author = {Cole, Nicholas and Louis, Sushil J and Miles, Chris},
booktitle = {Evolutionary Computation, 2004. CEC2004. Congress on},
keywords = {Counter Strike},
mendeley-tags = {Counter Strike},
organization = {IEEE},
pages = {139--145},
title = {{Using a genetic algorithm to tune first-person shooter bots}},
volume = {1},
year = {2004}
}
@inproceedings{dawes2005towards,
author = {Dawes, Mark and Hall, Richard},
booktitle = {Knowledge-Based Intelligent Information and Engineering Systems},
organization = {Springer},
pages = {276--282},
title = {{Towards using first-person shooter computer games as an artificial intelligence testbed}},
year = {2005}
}
@article; NN{el2007hybrid,
author = {{El Rhalibi}, Abdennour and Merabti, Madjid},
booktitle = {International Journal of Computer Games Technology},
keywords = {Quake 3 Arena},
mendeley-tags = {Quake 3 Arena},
publisher = {Hindawi Publishing Corporation},
title = {{A hybrid fuzzy ANN system for agent adaptation in a first person shooter}},
volume = {2008},
year = {2007}
}
@inproceedings{5586059,
abstract = {In this paper we employ a steady state genetic algorithm to evolve different types of behaviour for bots in the Unreal Tournament 2004™ computer game. For this purpose we define three fitness functions which are based on the number of enemies killed, the lifespan of the bot and a combination of both. Long run experiments were carried out, in which the evolved bots' behaviours outperform those of standard bots supplied by the game, particularly in those cases where the fitness involves a measure of the bot's lifespan. Also, there is an increase in the number of items collected, and the behaviours tend to become less aggressive, tending instead towards a more optimised combat style. Further “short run” experiments were carried out with a further type of fitness function defined, based on the number of items picked. In these cases the bots evolve performances towards the goal they have been aimed, with no other behaviours arising, except in the case of the multiple objective one. We conclude that in order to evolve interesting behaviours more complex fitness functions are needed, and not necessarily ones that directly include the goal we are aiming for.},
author = {Esparcia-Alcázar, A I and Martínez-García, A and Mora, A and Merelo, J J and García-Sánchez, P},
booktitle = {Evolutionary Computation (CEC), 2010 IEEE Congress on},
doi = {10.1109/CEC.2010.5586059},
keywords = {Artificial intelligence,Artificial neural networks,Biological cells,First Person Shooter game,Games,Humans,Steady-state,Unreal Tournament,Weapons,bots behaviour,computer game,computer games,fitness function,genetic algorithm,genetic algorithms},
mendeley-tags = {Unreal Tournament},
month = {jul},
pages = {1--8},
title = {{Controlling bots in a First Person Shooter game using genetic algorithms}},
year = {2010}
}
@phdthesis{geisler2002empirical,
author = {Geisler, Benjamin},
keywords = {Soldier of Fortune 2},
mendeley-tags = {Soldier of Fortune 2},
school = {Citeseer},
title = {{An empirical study of machine learning algorithms applied to modeling player behavior in a “first person shooter” video game}},
year = {2002}
}
@inproceedings{6314567,
abstract = {This paper describes an architecture for controlling non-player characters (NPC) in the First Person Shooter (FPS) game Unreal Tournament 2004. Specifically, the DRE-Bot architecture is made up of three reinforcement learners, Danger, Replenish and Explore, which use the tabular Sarsa($\lambda$) algorithm. This algorithm enables the NPC to learn through trial and error building up experience over time in an approach inspired by human learning. Experimentation is carried to measure the performance of DRE-Bot when competing against fixed strategy bots that ship with the game. The discount parameter, $\gamma$, and the trace parameter, $\lambda$, are also varied to see if their values have an effect on the performance.},
author = {Glavin, F G and Madden, M G},
booktitle = {Computer Games (CGAMES), 2012 17th International Conference on},
doi = {10.1109/CGames.2012.6314567},
keywords = {Computer architecture,Computers,DRE-Bot architecture,Danger,Educational institutions,Explore,FPS game Unreal Tournament 2004,First Person Shooter,Games,Humans,Learning,NPC,RL,Reinforcement Learning,Replenish,Unreal Tournament,Weapons,computer games,discount parameter,fixed strategy bots,hierarchical first person shooter bot,learning (artificial intelligence),multiple Sarsa($\lambda$) reinforcement learners,nonplayer characters,tabular Sarsa($\lambda$) algorithm,trace parameter},
mendeley-tags = {RL,Unreal Tournament},
month = {jul},
pages = {148--152},
title = {{DRE-Bot: A hierarchical First Person Shooter bot using multiple Sarsa( {\#}x03BB;) reinforcement learners}},
year = {2012}
}
@article{6922494,
author = {Glavin, F G and Madden, M G},
doi = {10.1109/TCIAIG.2014.2363042},
issn = {1943-068X},
journal = {Computational Intelligence and AI in Games, IEEE Transactions on},
keywords = {Avatars;Computer architecture;Computers;Games;Lear},
month = {jun},
number = {2},
pages = {180--192},
title = {{Adaptive Shooting for Bots in First Person Shooter Games Using Reinforcement Learning}},
volume = {7},
year = {2015}
}
@inproceedings{hirono2009implementation,
author = {Hirono, Daichi and Thawonmas, Ruck},
booktitle = {Proc. Asia Simulation Conference},
keywords = {Unreal Tournament},
mendeley-tags = {Unreal Tournament},
title = {{Implementation of a human-like bot in a first person shooter: second place bot at botprize 2008}},
volume = {2009},
year = {2009}
}
@inproceedings{5035619,
abstract = {A well-known Artificial Intelligence (AI) problem in video games is designing AI-controlled humanoid characters. It is desirable for these characters to appear both skillful and believably human-like. Many games address the former objective by providing their agents with unfair advantages. Although challenging, these agents are frustrating to humans who perceive the AI to be cheating. In this paper we evaluate hidden semi-Markov models and particle filters as a means for predicting opponent positions. Our results show that these models can perform with similar or better accuracy than the average human expert in the game Counter-Strike: Source. Furthermore, the mistakes these models make are more human-like than perfect predictions.},
author = {Hladky, S and Bulitko, V},
booktitle = {Computational Intelligence and Games, 2008. CIG '08. IEEE Symposium On},
doi = {10.1109/CIG.2008.5035619},
keywords = {Accuracy,Artificial intelligence,Clocks,Control systems,Counter Strike,Decision making,Game theory,Humans,Particle filters,Predictive models,Statistics,artificial intelligence,computer games,first-person shooter video game,hidden Markov models,hidden semi Markov model,multi-agent systems,opponent position prediction,particle filter},
mendeley-tags = {Counter Strike},
month = {dec},
pages = {39--46},
title = {{An evaluation of models for predicting opponent positions in first-person shooter video games}},
year = {2008}
}
@inproceedings{jaskiewicz2012prolog,
author = {Jaskiewicz, Grzegorz},
booktitle = {CS{\&}P},
keywords = {Counter Strike},
mendeley-tags = {Counter Strike},
pages = {170--181},
title = {{Prolog-Based Reasoning Layer for Counter-Strike Agents.}},
year = {2012}
}
@inproceedings{5035633,
abstract = {Reinforcement learning is well suited to first person shooter bot artificial intelligence as it has the potential to create diverse behaviors without the need to implicitly code them. This paper compares three different reinforcement learning approaches to create a bot with a universal behavior set. Results show that using a hierarchical or rule based approach, combined with reinforcement learning, is a promising solution to creating first person shooter bots that offer a rich and diverse behavior set.},
author = {McPartland, M and Gallagher, M},
booktitle = {Computational Intelligence and Games, 2008. CIG '08. IEEE Symposium On},
doi = {10.1109/CIG.2008.5035633},
keywords = {Artificial intelligence,Displays,Machine learning,Machine learning algorithms,Multiagent systems,Navigation,Network topology,RL,Robots,Statistics,Testing,artificial intelligence,computer games,learning (artificial intelligence),multipurpose first person shooter bot,reinforcement learning},
mendeley-tags = {RL},
month = {dec},
pages = {143--150},
title = {{Creating a multi-purpose first person shooter bot with reinforcement learning}},
year = {2008}
}
@article{5672586,
abstract = {Reinforcement learning (RL) is a popular machine learning technique that has many successes in learning how to play classic style games. Applying RL to first person shooter (FPS) games is an interesting area of research as it has the potential to create diverse behaviors without the need to implicitly code them. This paper investigates the tabular Sarsa ($\lambda$) RL algorithm applied to a purpose built FPS game. The first part of the research investigates using RL to learn bot controllers for the tasks of navigation, item collection, and combat individually. Results showed that the RL algorithm was able to learn a satisfactory strategy for navigation control, but not to the quality of the industry standard pathfinding algorithm. The combat controller performed well against a rule-based bot, indicating promising preliminary results for using RL in FPS games. The second part of the research used pretrained RL controllers and then combined them by a number of different methods to create a more generalized bot artificial intelligence (AI). The experimental results indicated that RL can be used in a generalized way to control a combination of tasks in FPS bots such as navigation, item collection, and combat.},
author = {McPartland, M and Gallagher, M},
doi = {10.1109/TCIAIG.2010.2100395},
issn = {1943-068X},
journal = {Computational Intelligence and AI in Games, IEEE Transactions on},
keywords = {Artificial intelligence (AI),RL,artificial intelligence,computer games,first person shooter game,industry standard pathfinding algorithm,knowledge based systems,learn bot controller,learning (artificial intelligence),machine learning,navigation control,path planning,reinforcement learning,reinforcement learning (RL),rule based bot,tabular Sarsa RL algorithm},
mendeley-tags = {RL},
month = {mar},
number = {1},
pages = {43--56},
title = {{Reinforcement Learning in First Person Shooter Games}},
volume = {3},
year = {2011}
}
@inproceedings{mcpartland2012interactively,
author = {McPartland, Michelle and Gallagher, Marcus},
booktitle = {Computational Intelligence and Games (CIG), 2012 IEEE Conference on},
organization = {IEEE},
pages = {132--138},
title = {{Interactively training first person shooter bots}},
year = {2012}
}
@incollection{mcpartland2012game,
author = {McPartland, Michelle and Gallagher, Marcus},
booktitle = {AI 2012: Advances in Artificial Intelligence},
keywords = {NN,RL},
mendeley-tags = {NN,RL},
pages = {397--408},
publisher = {Springer},
title = {{Game designers training first person shooter bots}},
year = {2012}
}
@inproceedings{overholtzer2005evolving,
author = {Overholtzer, C Adam and Levy, Simon D},
booktitle = {PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE},
keywords = {Cube},
mendeley-tags = {Cube},
number = {4},
organization = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
pages = {1620},
title = {{Evolving AI opponents in a first-person-shooter video game}},
volume = {20},
year = {2005}
}
@incollection{petrakis2010neural,
author = {Petrakis, Stelios and Tefas, Anastasios},
booktitle = {Artificial Neural Networks--ICANN 2010},
keywords = {Unreal Tournament},
mendeley-tags = {Unreal Tournament},
pages = {417--422},
publisher = {Springer},
title = {{Neural networks training for weapon selection in first-person shooter games}},
year = {2010}
}
@inproceedings{smith2007retaliate,
author = {Smith, Megan and Lee-Urban, Stephen and Mu{\~{n}}oz-Avila, H{\'{e}}ctor},
booktitle = {Proceedings of the National Conference on Artificial Intelligence},
keywords = {RL,Unreal Tournament},
mendeley-tags = {RL,Unreal Tournament},
number = {2},
organization = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
pages = {1801},
title = {{RETALIATE: learning winning policies in first-person shooter games}},
volume = {22},
year = {2007}
}
@article{smith2014continuous,
author = {Smith, Tony C and Miles, Jonathan},
journal = {Journal on Computing (JoC)},
keywords = {BZFlag},
mendeley-tags = {BZFlag},
number = {1},
title = {{Continuous and Reinforcement Learning Methods for First-Person Shooter Games}},
volume = {1},
year = {2014}
}
@inproceedings{6374144,
abstract = {One important aspect of creating game bots is adversarial motion planning: identifying how to move to counter possible actions made by the adversary. In this paper, we examine the problem of opponent interception, in which the goal of the bot is to reliably apprehend the opponent. We present an algorithm for motion planning that couples planning and prediction to intercept an enemy on a partially-occluded Unreal Tournament map. Human players can exhibit considerable variability in their movement preferences and do not uniformly prefer the same routes. To model this variability, we use inverse reinforcement learning to learn a player-specific motion model from sets of example traces. Opponent motion prediction is performed using a particle filter to track candidate hypotheses of the opponent's location over multiple time horizons. Our results indicate that the learned motion model has a higher tracking accuracy and yields better interception outcomes than other motion models and prediction methods.},
author = {Tastan, B and Chang, Yuan and Sukthankar, G},
booktitle = {Computational Intelligence and Games (CIG), 2012 IEEE Conference on},
doi = {10.1109/CIG.2012.6374144},
keywords = {Entropy,Games,Learning,Mathematical model,Tracking,Trajectory,Unreal Tournament,Vectors,adversarial motion planning,computer games,couples planning,first person shooter games,game bots,inverse reinforcement learning,learning (artificial intelligence),motion models,opponent interception,partially-occluded Unreal Tournament map,path planning,player-specific motion model,prediction methods,software agents},
mendeley-tags = {Unreal Tournament},
month = {sep},
pages = {100--107},
title = {{Learning to intercept opponents in first person shooter games}},
year = {2012}
}
@inproceedings{tastan2011learning,
author = {Tastan, Bulent and Sukthankar, Gita Reese},
booktitle = {AIIDE},
keywords = {Unreal Tournament},
organization = {Citeseer},
title = {{Learning Policies for First Person Shooter Games Using Inverse Reinforcement Learning.}},
year = {2011}
}
@inproceedings{6046867,
abstract = {The implementation of Artificial Intelligence (AI)in 3-Dimensional (3D) First Person Shooter (FPS) game is quite general nowadays. Most of the conventional AI bots created are mostly from hard coded AI bots. Hence, it has limited the dynamicity of the AI bots and therefore it brings to a fixed strategy for gaming. The main focus of this paper is to discuss the methodologies used in generating the AI bots that is competitive in the FPS gaming. In this paper, a decision making structure is proposed. It has been combined with the Evolutionary Programming in generating the required AI controllers. Hence, there are two methodology discussions involved: (1) the proposed decision making structure and (2)the Evolutionary Programming used. The experiments show highly promising testing results after the generated AI bots have been tested and compared with the conventional ruled based AI bots. It proves that the generated AI bots using the combination of Evolutionary Programming and decision making structure performed better than those AI bots generated using conventional ruled based strategy which is hard coded and time consuming to develop.},
author = {Tong, Chang Kee and Hui, Ong Jia and Teo, J and On, Chin Kim},
booktitle = {Bio-Inspired Computing: Theories and Applications (BIC-TA), 2011 Sixth International Conference on},
doi = {10.1109/BIC-TA.2011.71},
keywords = {3D FPS gaming,AI controller,Artificial Intelligence (AI),Artificial intelligence,Decision making,Engines,Evolutionary Algorithm (EA),Evolutionary Programming (EP),Evolutionary computation,First Person Shooter (FPS),Gamebots,Games,Humans,Three dimensional displays,Unreal Tournament,artificial intelligence,computer games,decision making,decision making structure,evolutionary computation,evolutionary programming,intelligent robots,knowledge based systems,rule based AI bots,three-dimensional first person shooter game},
mendeley-tags = {Unreal Tournament},
month = {sep},
pages = {21--26},
title = {{The Evolution of Gamebots for 3D First Person Shooter (FPS)}},
year = {2011}
}
@inproceedings{Hoorn2009hierachical,
abstract = {We describe the architecture of a hierarchical learning-based controller for bots in the First-Person Shooter (FPS) game Unreal Tournament 2004. The controller is inspired by the subsumption architecture commonly used in behaviour-based robotics. A behaviour selector decides which of three sub-controllers gets to control the bot at each time step. Each controller is implemented as a recurrent neural network, and trained with artificial evolution to perform respectively combat, exploration and path following. The behaviour selector is trained with a multiobjective evolutionary algorithm to achieve an effective balancing of the lower-level behaviours. We argue that FPS games provide good environments for studying the learning of complex behaviours, and that the methods proposed here can help developing interesting opponents for games.},
author = {van Hoorn, N and Togelius, J and Schmidhuber, J},
booktitle = {Computational Intelligence and Games, 2009. CIG 2009. IEEE Symposium on},
doi = {10.1109/CIG.2009.5286463},
keywords = {Artificial intelligence,Automata,Computational and artificial intelligence,Computer architecture,Evolutionary computation,FPS,First-person shooters,Humans,Navigation,Neural networks,RNN,Robots,Unreal Tournament,Unreal Tournament 2004,Weapons,action selection,behaviour selector,behaviour-based robotics,computer games,control engineering computing,evolutionary algorithms,evolutionary computation,first-person shooter game,hierarchical controller learning,learning (artificial intelligence),multiobjective evolutionary algorithm,neural networks,path following,recurrent neural nets,recurrent neural network,robots,subsumption architecture},
mendeley-tags = {RNN,Unreal Tournament},
month = {sep},
pages = {294--301},
title = {{Hierarchical controller learning in a First-Person Shooter}},
year = {2009}
}
@phdthesis{verweij2007hierarchically,
author = {Verweij, Tim and Schut, Martijn and Straatman, Remco and Guerrilla, B V},
keywords = {Killzone},
mendeley-tags = {Killzone},
school = {Master’s thesis, Vrije Universiteit of Amsterdam},
title = {{A hierarchically-layered multiplayer bot system for a first-person shooter}},
year = {2007}
}
@article{6849992,
author = {Wang, D and Tan, A.-H.},
doi = {10.1109/TCIAIG.2014.2336702},
issn = {1943-068X},
journal = {Computational Intelligence and AI in Games, IEEE Transactions on},
keywords = {Computers;Games;Learning (artificial intelligence)},
month = {jun},
number = {2},
pages = {123--138},
title = {{Creating Autonomous Adaptive Agents in a Real-Time First-Person Shooter Computer Game}},
volume = {7},
year = {2015}
}
@inproceedings{wang2009creating,
author = {Wang, Di and Subagdja, Budhitama and Tan, Ah-Hwee and Ng, Gee-Wah},
booktitle = {Proceedings, Twenty-First Annual Conference on Innovative Applications of Artificial Intelligence},
keywords = {NN,RL,Unreal Tournament},
mendeley-tags = {NN,RL,Unreal Tournament},
pages = {173--178},
title = {{Creating human-like autonomous players in real-time first person shooter computer games}},
year = {2009}
}
